{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libaries\n",
    "import os\n",
    "\n",
    "## Data analysis and wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "\n",
    "## Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import set_config\n",
    "from ydata_profiling import ProfileReport\n",
    "%matplotlib inline \n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "# Machine learning_ Classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# # Model selection\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n",
    "#Palette\n",
    "palette = ['#328ca9', '#0e6ea9', '#2c4ea3', '#193882', '#102446']\n",
    "\n",
    "# Set the style of the visualization\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Set the configuration of sklearn\n",
    "SEED = 42 # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "\n",
    "\n",
    "\n",
    "# Specify the data types for columns with mixed types\n",
    "dtype_spec = {\n",
    "    'cap-diameter': 'float16',\n",
    "    'stem-height': 'float16',\n",
    "    'stem-width': 'float16',\n",
    "    'does-bruise-or-bleed':'category',\n",
    "    'has-ring':'category'\n",
    "}\n",
    "\n",
    "train_df = pd.read_csv(r'Output\\train_cleaned.csv',dtype=dtype_spec)\n",
    "test_df = pd.read_csv(r'Output\\test_cleaned.csv',dtype=dtype_spec)\n",
    "y = pd.read_csv(r'Output\\target.csv',dtype='category')\n",
    "\n",
    "# visualizing pipeline\n",
    "set_config(display='diagram')\n",
    "\n",
    "from utils import PreprocessData\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Preprocess the data\n",
    "X, preprocessor = PreprocessData(train_df)\n",
    "X1, preprocessor = PreprocessData(test_df)\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y).ravel()  \n",
    "\n",
    "# Split the entire data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MCC\n",
    "\n",
    "models = {\n",
    "    # \"Logistic Regression\": LogisticRegression(random_state=SEED),\n",
    "    # \"Random Forest Classifier\": RandomForestClassifier(random_state=SEED),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(random_state=SEED),\n",
    "    # \"XGBClassifier\": XGBClassifier(random_state=SEED),\n",
    "    # \"MLP Classifier\": MLPClassifier(random_state=SEED),\n",
    "    # \"Extra Trees Classifier\": ExtraTreesClassifier(random_state=SEED),\n",
    "    # \"AdaBoost Classifier\": AdaBoostClassifier(estimator = DecisionTreeClassifier(max_depth=1), algorithm='SAMME',random_state=SEED),\n",
    "    # \"Dummy Classifier\": DummyClassifier(strategy='most_frequent',random_state=SEED)  # DummyClassifier for sanity check\n",
    "}\n",
    "\n",
    "\n",
    "print ('=' * 100)\n",
    "print ('Loading model:', list(models.keys())[i])\n",
    "with open((f\"/kaggle/working/{list(models.keys())[i]}\"+\"_tuning.pkl\" if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else f\"Output\\\\{list(models.keys())[i]}\"+\"_tuning.pkl\"), 'rb') as file:\n",
    "    model = load(file)\n",
    "print('Model-loading success:', list(models.keys())[i], 'Best Parameters:', model.get_params())\n",
    "\n",
    "\n",
    "print('Model-refitting:', list(models.keys())[i], 'Best Parameters:', model.get_params())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "print ('Predicting')\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate Train and val dataset\n",
    "MCC_train = MCC(y_train, y_train_pred)\n",
    "MCC_val = MCC(y_val, y_val_pred)\n",
    "\n",
    "print('Model prediction success:', list(models.keys())[i], 'MCC_train:', MCC_train, ' , MCC_val:', MCC_val)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
