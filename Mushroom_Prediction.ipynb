{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mushroom Prediction: A Preliminary Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px double #dcdcdc; padding: 10px; border-radius: 5px; background-color: #202020; max-width: 97.5%; overflow-x: auto;\">\n",
    "<h2> Version Log </h2>\n",
    "<p>\n",
    "<br>[5_8_2024]: Updated the data-cleaning process.\n",
    "<br>[4_8_2024]: Debugged the models and their parameters. Enhanced the code for better migration to kaggle\n",
    "<br>[3_8_2024]: Completed data preprocessing. Constructed and trained various base-lv models and ensembled into a meta-model. \n",
    "                Made prediction, MCC = 0.98\n",
    "<br>[2_8_2024]: Completed data cleaning \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a Juptyer notebook for the Kaggle Project: Mushroom Classification\n",
    "# %pip install ydata-profiling\n",
    "# %pip install numpy\n",
    "# %pip install --upgrade pandas\n",
    "# %pip install --upgrade matplotlib\n",
    "# %pip install --upgrade seaborn\n",
    "# %pip install --upgrade scikit-learn\n",
    "# %pip install --upgrade scipy\n",
    "# %pip install --upgrade catboost\n",
    "# %pip install --upgrade xgboost\n",
    "# %pip install --upgrade lightgbm\n",
    "# %pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libaries\n",
    "import os\n",
    "\n",
    "## Data analysis and wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "\n",
    "## Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import set_config\n",
    "from ydata_profiling import ProfileReport\n",
    "%matplotlib inline \n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "# Machine learning_ Classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# # Model selection\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n",
    "#Palette\n",
    "palette = ['#328ca9', '#0e6ea9', '#2c4ea3', '#193882', '#102446']\n",
    "\n",
    "# Set the style of the visualization\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Set the configuration of sklearn\n",
    "SEED = 42 # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Problem identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement:\n",
    "\n",
    "This is one of the 2024 playground competitions on Kaggle. \n",
    "\n",
    "The major goal of the project is to develope a classifier for classifying muchrooms into edible or poisonous based on physical characteristics presented in tabulated formats. \n",
    "The performance of the model will be assessed by the Matthews correlation coefficient (MCC), that is calculated by:\n",
    "\n",
    "$$MCC = \\frac{TP \\cdot TN - FP \\cdot FN}{\\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}}$$\n",
    "\n",
    "\n",
    "<br> Reference:\n",
    "<br> [1] Walter Reade, Ashley Chow. (2024). Binary Prediction of Poisonous Mushrooms. Kaggle. https://kaggle.com/competitions/playground-series-s4e8\n",
    "<br> [2] https://archive.ics.uci.edu/dataset/73/mushroom "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading data\n",
    "\n",
    "# Check if running on Kaggle\n",
    "if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
    "    train_df=pd.read_csv(r'/kaggle/input/playground-series-s4e8/train.csv')#\n",
    "    test_df=pd.read_csv(r'/kaggle/input/playground-series-s4e8/train.csv')#\n",
    "else:\n",
    "    train_df=pd.read_csv(r'Input\\train.csv')#\n",
    "    test_df=pd.read_csv(r'Input\\test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. The number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'class' 'cap-diameter' 'cap-shape' 'cap-surface' 'cap-color'\n",
      " 'does-bruise-or-bleed' 'gill-attachment' 'gill-spacing' 'gill-color'\n",
      " 'stem-height' 'stem-width' 'stem-root' 'stem-surface' 'stem-color'\n",
      " 'veil-type' 'veil-color' 'has-ring' 'ring-type' 'spore-print-color'\n",
      " 'habitat' 'season']\n",
      "(3116945, 22)\n"
     ]
    }
   ],
   "source": [
    "# Number of columns and rows in the dataset\n",
    "print(train_df.columns.values)\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #999999; padding: 10px; border-radius: 5px; background-color: #282828; max-width: 97.5%; overflow-x: auto;\">\n",
    "<p>\n",
    "<br> - There are 22 features in the 3116945 entries in the training dataset. \n",
    "<br> - The id is the index of the data entry; the class is the target variable and the others are features.  \n",
    "<br> - The cap, bruise, gill, stem, veil and ring are different parts of a mushroom that can be found in the anatomy shown below. \n",
    "<br> - From https://archive.ics.uci.edu/dataset/73/mushroom, the features included are described below. It is also known that, all entries in the categorial features should contain <b> exactly 1 letter </b>. \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "1. id                   = the index of the data entry\n",
    "2. class                = e (edible)/ p (poisonous) - <b>The target variable </b>\n",
    "3. cap-diameter         = The di\n",
    "4. cap-shape            = a shape descriptor of the mushroom's cap \n",
    "5. cap-surface          = a surface descriptor \n",
    "6. cap-color            = the color of the mushroom cap\n",
    "7. does-bruise-or-bleed = Will the mushroom change color when being bruised or cut \n",
    "8. gill-attachment      = Does the mushroom have gill attached\n",
    "9. gill-spacing         = the spacing of gill under the cap of mushroom  \n",
    "10. gill-color          = the color of the gill\n",
    "11. stem-height         = \n",
    "12. stem-width          = \n",
    "13. stem-root           = \n",
    "14. stem-surface        = \n",
    "15. stem-color          = the color of the stem\n",
    "16. veil-type           = the type of the veil \n",
    "17. veil-color          = the color of the veil\n",
    "18. has-ring            = the existance of rings\n",
    "19. ring-type           = the type of rings.\n",
    "20. spore-print-color   = the color of print of spore obtained by cutting the cap and gill and cover with a blank paper.\n",
    "21. habitat             = the habit of the mushrooms.\n",
    "22. season              = the season of obtaining the mushrooms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](<Anatomy of a Mushroom Graphic-1.webp>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>e</td>\n",
       "      <td>8.80</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>4.51</td>\n",
       "      <td>x</td>\n",
       "      <td>h</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>e</td>\n",
       "      <td>6.94</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>b</td>\n",
       "      <td>f</td>\n",
       "      <td>x</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>e</td>\n",
       "      <td>3.88</td>\n",
       "      <td>f</td>\n",
       "      <td>y</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>e</td>\n",
       "      <td>5.85</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>w</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id class  cap-diameter cap-shape cap-surface cap-color  \\\n",
       "0   0     e          8.80         f           s         u   \n",
       "1   1     p          4.51         x           h         o   \n",
       "2   2     e          6.94         f           s         b   \n",
       "3   3     e          3.88         f           y         g   \n",
       "4   4     e          5.85         x           l         w   \n",
       "\n",
       "  does-bruise-or-bleed gill-attachment gill-spacing gill-color  ...  \\\n",
       "0                    f               a            c          w  ...   \n",
       "1                    f               a            c          n  ...   \n",
       "2                    f               x            c          w  ...   \n",
       "3                    f               s          NaN          g  ...   \n",
       "4                    f               d          NaN          w  ...   \n",
       "\n",
       "   stem-root  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n",
       "0        NaN           NaN          w       NaN        NaN        f         f   \n",
       "1        NaN             y          o       NaN        NaN        t         z   \n",
       "2        NaN             s          n       NaN        NaN        f         f   \n",
       "3        NaN           NaN          w       NaN        NaN        f         f   \n",
       "4        NaN           NaN          w       NaN        NaN        f         f   \n",
       "\n",
       "  spore-print-color habitat season  \n",
       "0               NaN       d      a  \n",
       "1               NaN       d      w  \n",
       "2               NaN       l      w  \n",
       "3               NaN       d      u  \n",
       "4               NaN       g      a  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first 5 rows of the dataset\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3116940</th>\n",
       "      <td>3116940</td>\n",
       "      <td>e</td>\n",
       "      <td>9.29</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>u</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116941</th>\n",
       "      <td>3116941</td>\n",
       "      <td>e</td>\n",
       "      <td>10.88</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>p</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116942</th>\n",
       "      <td>3116942</td>\n",
       "      <td>p</td>\n",
       "      <td>7.82</td>\n",
       "      <td>x</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116943</th>\n",
       "      <td>3116943</td>\n",
       "      <td>e</td>\n",
       "      <td>9.45</td>\n",
       "      <td>p</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>p</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116944</th>\n",
       "      <td>3116944</td>\n",
       "      <td>p</td>\n",
       "      <td>3.20</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id class  cap-diameter cap-shape cap-surface cap-color  \\\n",
       "3116940  3116940     e          9.29         f         NaN         n   \n",
       "3116941  3116941     e         10.88         s         NaN         w   \n",
       "3116942  3116942     p          7.82         x           e         e   \n",
       "3116943  3116943     e          9.45         p           i         n   \n",
       "3116944  3116944     p          3.20         x           s         g   \n",
       "\n",
       "        does-bruise-or-bleed gill-attachment gill-spacing gill-color  ...  \\\n",
       "3116940                    t             NaN          NaN          w  ...   \n",
       "3116941                    t               d            c          p  ...   \n",
       "3116942                    f               a          NaN          w  ...   \n",
       "3116943                    t               e          NaN          p  ...   \n",
       "3116944                    f               d            c          w  ...   \n",
       "\n",
       "         stem-root  stem-surface stem-color veil-type veil-color has-ring  \\\n",
       "3116940          b           NaN          w         u          w        t   \n",
       "3116941        NaN           NaN          w       NaN        NaN        f   \n",
       "3116942        NaN           NaN          y       NaN          w        t   \n",
       "3116943        NaN             y          w       NaN        NaN        t   \n",
       "3116944        NaN           NaN          w       NaN        NaN        f   \n",
       "\n",
       "        ring-type spore-print-color habitat season  \n",
       "3116940         g               NaN       d      u  \n",
       "3116941         f               NaN       d      u  \n",
       "3116942         z               NaN       d      a  \n",
       "3116943         p               NaN       d      u  \n",
       "3116944         f               NaN       g      u  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the last 5 rows of the dataset\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Data type of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3116945 entries, 0 to 3116944\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   id                    int64  \n",
      " 1   class                 object \n",
      " 2   cap-diameter          float64\n",
      " 3   cap-shape             object \n",
      " 4   cap-surface           object \n",
      " 5   cap-color             object \n",
      " 6   does-bruise-or-bleed  object \n",
      " 7   gill-attachment       object \n",
      " 8   gill-spacing          object \n",
      " 9   gill-color            object \n",
      " 10  stem-height           float64\n",
      " 11  stem-width            float64\n",
      " 12  stem-root             object \n",
      " 13  stem-surface          object \n",
      " 14  stem-color            object \n",
      " 15  veil-type             object \n",
      " 16  veil-color            object \n",
      " 17  has-ring              object \n",
      " 18  ring-type             object \n",
      " 19  spore-print-color     object \n",
      " 20  habitat               object \n",
      " 21  season                object \n",
      "dtypes: float64(3), int64(1), object(18)\n",
      "memory usage: 523.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #999999; padding: 10px; border-radius: 5px; background-color: #282828; max-width: 97.5%; overflow-x: auto;\">\n",
    "<p>\n",
    "<br> It is observed that most of the variables are categoiral, except id, cap-diameter , stem-height and stem-width, which are numerical.  </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3116945</td>\n",
       "      <td>3116905</td>\n",
       "      <td>2445922</td>\n",
       "      <td>3116933</td>\n",
       "      <td>3116937</td>\n",
       "      <td>2593009</td>\n",
       "      <td>1858510</td>\n",
       "      <td>3116888</td>\n",
       "      <td>359922</td>\n",
       "      <td>1136084</td>\n",
       "      <td>3116907</td>\n",
       "      <td>159452</td>\n",
       "      <td>375998</td>\n",
       "      <td>3116921</td>\n",
       "      <td>2988065</td>\n",
       "      <td>267263</td>\n",
       "      <td>3116900</td>\n",
       "      <td>3116945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>83</td>\n",
       "      <td>78</td>\n",
       "      <td>26</td>\n",
       "      <td>78</td>\n",
       "      <td>48</td>\n",
       "      <td>63</td>\n",
       "      <td>38</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>u</td>\n",
       "      <td>w</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>k</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1705396</td>\n",
       "      <td>1436026</td>\n",
       "      <td>460777</td>\n",
       "      <td>1359542</td>\n",
       "      <td>2569743</td>\n",
       "      <td>646034</td>\n",
       "      <td>1331054</td>\n",
       "      <td>931538</td>\n",
       "      <td>165801</td>\n",
       "      <td>327610</td>\n",
       "      <td>1196637</td>\n",
       "      <td>159373</td>\n",
       "      <td>279070</td>\n",
       "      <td>2368820</td>\n",
       "      <td>2477170</td>\n",
       "      <td>107310</td>\n",
       "      <td>2177573</td>\n",
       "      <td>1543321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          class cap-shape cap-surface cap-color does-bruise-or-bleed  \\\n",
       "count   3116945   3116905     2445922   3116933              3116937   \n",
       "unique        2        74          83        78                   26   \n",
       "top           p         x           t         n                    f   \n",
       "freq    1705396   1436026      460777   1359542              2569743   \n",
       "\n",
       "       gill-attachment gill-spacing gill-color stem-root stem-surface  \\\n",
       "count          2593009      1858510    3116888    359922      1136084   \n",
       "unique              78           48         63        38           60   \n",
       "top                  a            c          w         b            s   \n",
       "freq            646034      1331054     931538    165801       327610   \n",
       "\n",
       "       stem-color veil-type veil-color has-ring ring-type spore-print-color  \\\n",
       "count     3116907    159452     375998  3116921   2988065            267263   \n",
       "unique         59        22         24       23        40                32   \n",
       "top             w         u          w        f         f                 k   \n",
       "freq      1196637    159373     279070  2368820   2477170            107310   \n",
       "\n",
       "        habitat   season  \n",
       "count   3116900  3116945  \n",
       "unique       52        4  \n",
       "top           d        a  \n",
       "freq    2177573  1543321  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the unique values and the count of unique values in the dataset\n",
    "train_df.describe(include=['O'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Handling missing, distinct and duplicated entries:\n",
    "\n",
    "#### 4.3.1 Number of Missing/ distinct and duplicated entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data in the training dataset (%)\n",
      "====================================================================================================\n",
      "veil-type               94.884\n",
      "spore-print-color       91.425\n",
      "stem-root               88.453\n",
      "veil-color              87.937\n",
      "stem-surface            63.551\n",
      "gill-spacing            40.374\n",
      "cap-surface             21.528\n",
      "gill-attachment         16.809\n",
      "ring-type                4.135\n",
      "gill-color               0.002\n",
      "habitat                  0.001\n",
      "cap-shape                0.001\n",
      "stem-color               0.001\n",
      "has-ring                 0.001\n",
      "cap-color                0.000\n",
      "does-bruise-or-bleed     0.000\n",
      "cap-diameter             0.000\n",
      "id                       0.000\n",
      "stem-width               0.000\n",
      "class                    0.000\n",
      "stem-height              0.000\n",
      "season                   0.000\n",
      "dtype: float64\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing Data in the training dataset (%)\")\n",
    "print(\"=\"*100)\n",
    "print((train_df.isnull().sum()/len(train_df)*100).sort_values(ascending = False).round(3))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Data in the training dataset (%)\n",
      "====================================================================================================\n",
      "id                      3116945\n",
      "stem-width                 5836\n",
      "cap-diameter               3913\n",
      "stem-height                2749\n",
      "cap-surface                  83\n",
      "cap-color                    78\n",
      "gill-attachment              78\n",
      "cap-shape                    74\n",
      "gill-color                   63\n",
      "stem-surface                 60\n",
      "stem-color                   59\n",
      "habitat                      52\n",
      "gill-spacing                 48\n",
      "ring-type                    40\n",
      "stem-root                    38\n",
      "spore-print-color            32\n",
      "does-bruise-or-bleed         26\n",
      "veil-color                   24\n",
      "has-ring                     23\n",
      "veil-type                    22\n",
      "season                        4\n",
      "class                         2\n",
      "dtype: int64\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Distinct Data in the training dataset (%)\")\n",
    "print(\"=\"*100)\n",
    "print(train_df.nunique().sort_values(ascending = False))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated Data in the training dataset (%)\n",
      "====================================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuplicated Data in the training dataset (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m((train_df\u001b[38;5;241m.\u001b[39mduplicated()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_df)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\pandas\\core\\frame.py:6958\u001b[0m, in \u001b[0;36mDataFrame.duplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   6956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6957\u001b[0m     vals \u001b[38;5;241m=\u001b[39m (col\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m name, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m subset)\n\u001b[1;32m-> 6958\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(f, vals)))\n\u001b[0;32m   6960\u001b[0m     ids \u001b[38;5;241m=\u001b[39m get_group_index(labels, \u001b[38;5;28mtuple\u001b[39m(shape), sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, xnull\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   6961\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced(duplicated(ids, keep), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\pandas\\core\\frame.py:6926\u001b[0m, in \u001b[0;36mDataFrame.duplicated.<locals>.f\u001b[1;34m(vals)\u001b[0m\n\u001b[0;32m   6925\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(vals) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m-> 6926\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m algorithms\u001b[38;5;241m.\u001b[39mfactorize(vals, size_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m   6927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;28mlen\u001b[39m(shape)\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\pandas\\core\\algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[0;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[1;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m factorize_array(\n\u001b[0;32m    796\u001b[0m         values,\n\u001b[0;32m    797\u001b[0m         use_na_sentinel\u001b[38;5;241m=\u001b[39muse_na_sentinel,\n\u001b[0;32m    798\u001b[0m         size_hint\u001b[38;5;241m=\u001b[39msize_hint,\n\u001b[0;32m    799\u001b[0m     )\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[0;32m    803\u001b[0m         uniques,\n\u001b[0;32m    804\u001b[0m         codes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    808\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\pandas\\core\\algorithms.py:604\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfactorize(\n\u001b[0;32m    596\u001b[0m     values,\n\u001b[0;32m    597\u001b[0m     na_sentinel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    600\u001b[0m     ignore_na\u001b[38;5;241m=\u001b[39muse_na_sentinel,\n\u001b[0;32m    601\u001b[0m )\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[1;32m--> 604\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[0;32m    606\u001b[0m codes \u001b[38;5;241m=\u001b[39m ensure_platform_int(codes)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\pandas\\core\\algorithms.py:184\u001b[0m, in \u001b[0;36m_reconstruct_data\u001b[1;34m(values, dtype, original)\u001b[0m\n\u001b[0;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ensure_object(values)\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reconstruct_data\u001b[39m(\n\u001b[0;32m    185\u001b[0m     values: ArrayLike, dtype: DtypeObj, original: AnyArrayLike\n\u001b[0;32m    186\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m    reverse of _ensure_data\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m    ExtensionArray or np.ndarray\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, ABCExtensionArray) \u001b[38;5;129;01mand\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtype:\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;66;03m# Catch DatetimeArray/TimedeltaArray\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Duplicated Data in the training dataset (%)\")\n",
    "print(\"=\"*100)\n",
    "print((train_df.duplicated().sum()/len(train_df)*100).round(3))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #999999; padding: 10px; border-radius: 5px; background-color: #282828; max-width: 97.5%; overflow-x: auto;\">\n",
    "<p>\n",
    "<br>  There are multiple missing values in the data with some of them contribute a large portion of the entries (e.g. veil-type & spore-print-color). </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Understand the cause and type of missing data. \n",
    "\n",
    "- Different types of missing data may leads to different handling methods. Following are some examples of missing data and their handling methods.\n",
    "\n",
    "    - Missing Completely at Random (MCAR):\n",
    "        - Handling method: Simple imputation\n",
    "        - Cause: The probability of missing an entry is completely independent of the values of the variables in the dataset, as well as the unobserved data.\n",
    "        - Example: a sensor malfunctions and randomly fails to record some measurements\n",
    "    \n",
    "    - Missing at Random (MAR): \n",
    "        - Handling method: advanced imputation techniques\n",
    "        - Cause: The probability of a data point being missing depends on the observed variables in the dataset, but not on the unobserved (missing) data.\n",
    "        - Example: income data is more likely to be missing for individuals with lower education levels\n",
    "    \n",
    "    - Missing Not at Random (MNAR):\n",
    "        - Handling methods: pattern mixture models or selection models\n",
    "        - Causes: the probability of a data point being missing depends on the unobserved (missing) data itself.\n",
    "        - Example: individuals with higher income are less likely to report their income\n",
    "        \n",
    "    - Systematic Missing Data:\n",
    "        - Handling methods: Simple imputation or creating Proxy variable\n",
    "    - Causes: An entire variables or features are missing from the dataset, typically due to issues in data collection or data processing.\n",
    "    - Example: A sensor was not installed on certain devices, resulting in the absence of data for a specific feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #999999; padding: 10px; border-radius: 5px; background-color: #282828; max-width: 97.5%; overflow-x: auto;\">\n",
    "<p>\n",
    "<br> - By inspecting the entries in various columns, it is found that there are categoiral features having entries with digits/ more than one letters, which might due to issues in data collection or data processing. \n",
    "<br>\n",
    "<br> - Therefore, it is decided that we will impute these entries with the most frequent option in the column. To reduce cardinality, it is also decide to gather all options which contributes to less than 5% of the column count into a new category \"Other\".</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Handling of the missing/distinct/diplicated data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Id' colum since it's unnecessary for the prediction process\n",
    "train_df = train_df.drop(['id'], axis=1)\n",
    "test_df = test_df.drop(['id'], axis=1)\n",
    "\n",
    "# Drop features that have > 50% missing values\n",
    "train_df = train_df.dropna(thresh=0.5*len(train_df), axis=1)\n",
    "\n",
    "# Drop the 'target' column and assign it to the target variable\n",
    "y = train_df['class']\n",
    "train_df = train_df.drop(['class'], axis=1)\n",
    "\n",
    "# Drop the same features in the test dataset\n",
    "test_df = test_df[train_df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m train_df \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mreplace({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFalse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m}, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m test_df \u001b[38;5;241m=\u001b[39m test_df\u001b[38;5;241m.\u001b[39mreplace({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^.*[^a-zA-Z].*$\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mnan, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^.\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m2,}$\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mnan}, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 9\u001b[0m test_df \u001b[38;5;241m=\u001b[39m test_df\u001b[38;5;241m.\u001b[39mreplace({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFalse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m}, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Inspect the % of distinct values in the categorical columns\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistinct Data in the training dataset (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\pandas\\core\\generic.py:8051\u001b[0m, in \u001b[0;36mNDFrame.replace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   8048\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   8049\u001b[0m         to_replace, value \u001b[38;5;241m=\u001b[39m keys, values\n\u001b[1;32m-> 8051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplace(\n\u001b[0;32m   8052\u001b[0m         to_replace, value, inplace\u001b[38;5;241m=\u001b[39minplace, limit\u001b[38;5;241m=\u001b[39mlimit, regex\u001b[38;5;241m=\u001b[39mregex\n\u001b[0;32m   8053\u001b[0m     )\n\u001b[0;32m   8054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   8055\u001b[0m     \u001b[38;5;66;03m# need a non-zero len on all axes\u001b[39;00m\n\u001b[0;32m   8056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize:\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\pandas\\core\\generic.py:8099\u001b[0m, in \u001b[0;36mNDFrame.replace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   8094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(to_replace) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value):\n\u001b[0;32m   8095\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   8096\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReplacement lists must match in length. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   8097\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(to_replace)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   8098\u001b[0m         )\n\u001b[1;32m-> 8099\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreplace_list(\n\u001b[0;32m   8100\u001b[0m         src_list\u001b[38;5;241m=\u001b[39mto_replace,\n\u001b[0;32m   8101\u001b[0m         dest_list\u001b[38;5;241m=\u001b[39mvalue,\n\u001b[0;32m   8102\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   8103\u001b[0m         regex\u001b[38;5;241m=\u001b[39mregex,\n\u001b[0;32m   8104\u001b[0m     )\n\u001b[0;32m   8106\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m to_replace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   8107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   8108\u001b[0m         is_re_compilable(regex)\n\u001b[0;32m   8109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_list_like(regex)\n\u001b[0;32m   8110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_dict_like(regex)\n\u001b[0;32m   8111\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\pandas\\core\\internals\\base.py:278\u001b[0m, in \u001b[0;36mDataManager.replace_list\u001b[1;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"do a list replace\"\"\"\u001b[39;00m\n\u001b[0;32m    276\u001b[0m inplace \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(inplace, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 278\u001b[0m bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_with_block(\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace_list\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    280\u001b[0m     src_list\u001b[38;5;241m=\u001b[39msrc_list,\n\u001b[0;32m    281\u001b[0m     dest_list\u001b[38;5;241m=\u001b[39mdest_list,\n\u001b[0;32m    282\u001b[0m     inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m    283\u001b[0m     regex\u001b[38;5;241m=\u001b[39mregex,\n\u001b[0;32m    284\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    285\u001b[0m     already_warned\u001b[38;5;241m=\u001b[39m_AlreadyWarned(),\n\u001b[0;32m    286\u001b[0m )\n\u001b[0;32m    287\u001b[0m bm\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bm\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1101\u001b[0m, in \u001b[0;36mBlock.replace_list\u001b[1;34m(self, src_list, dest_list, inplace, regex, using_cow, already_warned)\u001b[0m\n\u001b[0;32m   1098\u001b[0m         already_warned\u001b[38;5;241m.\u001b[39mwarned_already \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m opt \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuture.no_silent_downcasting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, ((src, dest), mask) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(pairs, masks)):\n\u001b[0;32m   1102\u001b[0m     convert \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m==\u001b[39m src_len  \u001b[38;5;66;03m# only convert once at the end\u001b[39;00m\n\u001b[0;32m   1103\u001b[0m     new_rb: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1064\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_string_dtype(values\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;66;03m# Calculate the mask once, prior to the call of comp\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;66;03m# in order to avoid repeating the same computations\u001b[39;00m\n\u001b[0;32m   1059\u001b[0m     na_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39misna(values)\n\u001b[0;32m   1060\u001b[0m     masks: Iterable[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_]] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1061\u001b[0m         extract_bool_array(\n\u001b[0;32m   1062\u001b[0m             cast(\n\u001b[0;32m   1063\u001b[0m                 ArrayLike,\n\u001b[1;32m-> 1064\u001b[0m                 compare_or_regex_search(\n\u001b[0;32m   1065\u001b[0m                     values, s[\u001b[38;5;241m0\u001b[39m], regex\u001b[38;5;241m=\u001b[39mregex, mask\u001b[38;5;241m=\u001b[39mna_mask\n\u001b[0;32m   1066\u001b[0m                 ),\n\u001b[0;32m   1067\u001b[0m             )\n\u001b[0;32m   1068\u001b[0m         )\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m pairs\n\u001b[0;32m   1070\u001b[0m     )\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;66;03m# GH#38086 faster if we know we dont need to check for regex\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m     masks \u001b[38;5;241m=\u001b[39m (missing\u001b[38;5;241m.\u001b[39mmask_missing(values, s[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m pairs)\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\pandas\\core\\array_algos\\replace.py:98\u001b[0m, in \u001b[0;36mcompare_or_regex_search\u001b[1;34m(a, b, regex, mask)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     96\u001b[0m     a \u001b[38;5;241m=\u001b[39m a[mask]\n\u001b[1;32m---> 98\u001b[0m result \u001b[38;5;241m=\u001b[39m op(a)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# The shape of the mask can differ to that of the result\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# since we may compare only a subset of a's or b's elements\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(mask\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\numpy\\lib\\function_base.py:2372\u001b[0m, in \u001b[0;36mvectorize.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_stage_2(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m-> 2372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_as_normal(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\numpy\\lib\\function_base.py:2365\u001b[0m, in \u001b[0;36mvectorize._call_as_normal\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2362\u001b[0m     vargs \u001b[38;5;241m=\u001b[39m [args[_i] \u001b[38;5;28;01mfor\u001b[39;00m _i \u001b[38;5;129;01min\u001b[39;00m inds]\n\u001b[0;32m   2363\u001b[0m     vargs\u001b[38;5;241m.\u001b[39mextend([kwargs[_n] \u001b[38;5;28;01mfor\u001b[39;00m _n \u001b[38;5;129;01min\u001b[39;00m names])\n\u001b[1;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorize_call(func\u001b[38;5;241m=\u001b[39mfunc, args\u001b[38;5;241m=\u001b[39mvargs)\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\numpy\\lib\\function_base.py:2455\u001b[0m, in \u001b[0;36mvectorize._vectorize_call\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2452\u001b[0m \u001b[38;5;66;03m# Convert args to object arrays first\u001b[39;00m\n\u001b[0;32m   2453\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [asanyarray(a, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m-> 2455\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ufunc(\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   2457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mnout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2458\u001b[0m     res \u001b[38;5;241m=\u001b[39m asanyarray(outputs, dtype\u001b[38;5;241m=\u001b[39motypes[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\pandas\\core\\array_algos\\replace.py:89\u001b[0m, in \u001b[0;36mcompare_or_regex_search.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     86\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: operator\u001b[38;5;241m.\u001b[39meq(x, b)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     88\u001b[0m     op \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvectorize(\n\u001b[1;32m---> 89\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mbool\u001b[39m(re\u001b[38;5;241m.\u001b[39msearch(b, x))\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mstr\u001b[39m, Pattern))\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     )\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# GH#32621 use mask to avoid comparing to NAs\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\re\\__init__.py:173\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Try to apply the pattern to all of the string, returning\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags)\u001b[38;5;241m.\u001b[39mfullmatch(string)\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    174\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags)\u001b[38;5;241m.\u001b[39msearch(string)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Separate the numerical and categorical columns\n",
    "numerical_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = train_df.select_dtypes(include=[object]).columns.tolist()\n",
    "\n",
    "# Replace entries containing special characters, or string with a length larger than 1 with NaN\n",
    "train_df = train_df.replace({'^.*[^a-zA-Z].*$': np.nan, '^.{2,}$': np.nan}, regex=True)\n",
    "train_df = train_df.replace({'f': 'False', 't': 'True'}, regex=True)\n",
    "test_df = test_df.replace({'^.*[^a-zA-Z].*$': np.nan, '^.{2,}$': np.nan}, regex=True)\n",
    "test_df = test_df.replace({'f': 'False', 't': 'True'}, regex=True)\n",
    "\n",
    "# Inspect the % of distinct values in the categorical columns\n",
    "print(\"Distinct Data in the training dataset (%)\")\n",
    "print(\"=\"*100)\n",
    "print(train_df.nunique().sort_values(ascending = False))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gill-color\n",
       "w        0.298874\n",
       "n        0.174340\n",
       "y        0.150623\n",
       "p        0.110249\n",
       "g        0.068071\n",
       "o        0.050410\n",
       "k        0.041058\n",
       "False    0.038403\n",
       "r        0.020148\n",
       "e        0.017982\n",
       "b        0.015159\n",
       "u        0.014566\n",
       "l        0.000018\n",
       "d        0.000017\n",
       "True     0.000017\n",
       "s        0.000015\n",
       "x        0.000011\n",
       "c        0.000010\n",
       "a        0.000009\n",
       "h        0.000008\n",
       "z        0.000005\n",
       "m        0.000005\n",
       "i        0.000003\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the unique values in the one selected column\n",
    "percentage = train_df['gill-color'].value_counts(normalize=True)\n",
    "percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.80</td>\n",
       "      <td>False</td>\n",
       "      <td>s</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>4.51</td>\n",
       "      <td>15.39</td>\n",
       "      <td>w</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.51</td>\n",
       "      <td>x</td>\n",
       "      <td>h</td>\n",
       "      <td>o</td>\n",
       "      <td>False</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>4.79</td>\n",
       "      <td>6.48</td>\n",
       "      <td>Other</td>\n",
       "      <td>True</td>\n",
       "      <td>Other</td>\n",
       "      <td>d</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.94</td>\n",
       "      <td>False</td>\n",
       "      <td>s</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>x</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>6.85</td>\n",
       "      <td>9.93</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>l</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.88</td>\n",
       "      <td>False</td>\n",
       "      <td>y</td>\n",
       "      <td>g</td>\n",
       "      <td>False</td>\n",
       "      <td>s</td>\n",
       "      <td>Other</td>\n",
       "      <td>g</td>\n",
       "      <td>4.16</td>\n",
       "      <td>6.53</td>\n",
       "      <td>w</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.85</td>\n",
       "      <td>x</td>\n",
       "      <td>Other</td>\n",
       "      <td>w</td>\n",
       "      <td>False</td>\n",
       "      <td>d</td>\n",
       "      <td>Other</td>\n",
       "      <td>w</td>\n",
       "      <td>3.37</td>\n",
       "      <td>8.36</td>\n",
       "      <td>w</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>g</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116940</th>\n",
       "      <td>9.29</td>\n",
       "      <td>False</td>\n",
       "      <td>Other</td>\n",
       "      <td>n</td>\n",
       "      <td>True</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>w</td>\n",
       "      <td>12.14</td>\n",
       "      <td>18.81</td>\n",
       "      <td>w</td>\n",
       "      <td>True</td>\n",
       "      <td>Other</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116941</th>\n",
       "      <td>10.88</td>\n",
       "      <td>s</td>\n",
       "      <td>Other</td>\n",
       "      <td>w</td>\n",
       "      <td>True</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>p</td>\n",
       "      <td>6.65</td>\n",
       "      <td>26.97</td>\n",
       "      <td>w</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116942</th>\n",
       "      <td>7.82</td>\n",
       "      <td>x</td>\n",
       "      <td>Other</td>\n",
       "      <td>e</td>\n",
       "      <td>False</td>\n",
       "      <td>a</td>\n",
       "      <td>Other</td>\n",
       "      <td>w</td>\n",
       "      <td>9.51</td>\n",
       "      <td>11.06</td>\n",
       "      <td>y</td>\n",
       "      <td>True</td>\n",
       "      <td>Other</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116943</th>\n",
       "      <td>9.45</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>n</td>\n",
       "      <td>True</td>\n",
       "      <td>e</td>\n",
       "      <td>Other</td>\n",
       "      <td>p</td>\n",
       "      <td>9.13</td>\n",
       "      <td>17.77</td>\n",
       "      <td>w</td>\n",
       "      <td>True</td>\n",
       "      <td>Other</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116944</th>\n",
       "      <td>3.20</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>False</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>2.82</td>\n",
       "      <td>7.79</td>\n",
       "      <td>w</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>g</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3116945 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cap-diameter cap-shape cap-surface cap-color does-bruise-or-bleed  \\\n",
       "0                8.80     False           s     Other                False   \n",
       "1                4.51         x           h         o                False   \n",
       "2                6.94     False           s     Other                False   \n",
       "3                3.88     False           y         g                False   \n",
       "4                5.85         x       Other         w                False   \n",
       "...               ...       ...         ...       ...                  ...   \n",
       "3116940          9.29     False       Other         n                 True   \n",
       "3116941         10.88         s       Other         w                 True   \n",
       "3116942          7.82         x       Other         e                False   \n",
       "3116943          9.45     Other       Other         n                 True   \n",
       "3116944          3.20         x           s         g                False   \n",
       "\n",
       "        gill-attachment gill-spacing gill-color  stem-height  stem-width  \\\n",
       "0                     a            c          w         4.51       15.39   \n",
       "1                     a            c          n         4.79        6.48   \n",
       "2                     x            c          w         6.85        9.93   \n",
       "3                     s        Other          g         4.16        6.53   \n",
       "4                     d        Other          w         3.37        8.36   \n",
       "...                 ...          ...        ...          ...         ...   \n",
       "3116940           Other        Other          w        12.14       18.81   \n",
       "3116941               d            c          p         6.65       26.97   \n",
       "3116942               a        Other          w         9.51       11.06   \n",
       "3116943               e        Other          p         9.13       17.77   \n",
       "3116944               d            c          w         2.82        7.79   \n",
       "\n",
       "        stem-color has-ring ring-type habitat season  \n",
       "0                w    False     False       d      a  \n",
       "1            Other     True     Other       d      w  \n",
       "2                n    False     False       l      w  \n",
       "3                w    False     False       d      u  \n",
       "4                w    False     False       g      a  \n",
       "...            ...      ...       ...     ...    ...  \n",
       "3116940          w     True     Other       d      u  \n",
       "3116941          w    False     False       d      u  \n",
       "3116942          y     True     Other       d      a  \n",
       "3116943          w     True     Other       d      u  \n",
       "3116944          w    False     False       g      u  \n",
       "\n",
       "[3116945 rows x 15 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the entries in the categorical columns if they contribute to more than 5% of the data in the column, otherwise replace them with 'Other'\n",
    "for col in categorical_cols:\n",
    "    threshold = 0.05\n",
    "    value_counts = train_df[col].value_counts(normalize=True)\n",
    "    labels_to_keep = value_counts[value_counts > threshold].index.tolist()\n",
    "    train_df[col] = np.where(train_df[col].isin(labels_to_keep), train_df[col], 'Other')\n",
    "    test_df[col] = np.where(test_df[col].isin(labels_to_keep), test_df[col], 'Other')\n",
    "\n",
    "# Check the unique values in the categorical columns\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Data in the training dataset (%)\n",
      "====================================================================================================\n",
      "stem-width              5836\n",
      "cap-diameter            3913\n",
      "stem-height             2749\n",
      "cap-surface                8\n",
      "cap-color                  7\n",
      "gill-attachment            7\n",
      "gill-color                 7\n",
      "cap-shape                  5\n",
      "gill-spacing               4\n",
      "stem-color                 4\n",
      "habitat                    4\n",
      "season                     4\n",
      "does-bruise-or-bleed       3\n",
      "has-ring                   3\n",
      "ring-type                  2\n",
      "dtype: int64\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check the unique values in the categorical columns\n",
    "print(\"Distinct Data in the training dataset (%)\")\n",
    "print(\"=\"*100)\n",
    "print(train_df.nunique().sort_values(ascending = False))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gill-color\n",
       "w        0.298863\n",
       "n        0.174333\n",
       "y        0.150617\n",
       "Other    0.147467\n",
       "p        0.110244\n",
       "g        0.068068\n",
       "o        0.050408\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the unique values in the one selected column\n",
    "percentage = train_df['gill-color'].value_counts(normalize=True)\n",
    "percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kai Qi Yan\\AppData\\Local\\Temp\\ipykernel_13764\\2624352622.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna(train_df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\Kai Qi Yan\\AppData\\Local\\Temp\\ipykernel_13764\\2624352622.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[col].fillna(test_df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data in the training dataset (%)\n",
      "====================================================================================================\n",
      "cap-diameter            0.0\n",
      "cap-shape               0.0\n",
      "cap-surface             0.0\n",
      "cap-color               0.0\n",
      "does-bruise-or-bleed    0.0\n",
      "gill-attachment         0.0\n",
      "gill-spacing            0.0\n",
      "gill-color              0.0\n",
      "stem-height             0.0\n",
      "stem-width              0.0\n",
      "stem-color              0.0\n",
      "has-ring                0.0\n",
      "ring-type               0.0\n",
      "habitat                 0.0\n",
      "season                  0.0\n",
      "dtype: float64\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# imputate missing values\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].isnull().sum() > 0:\n",
    "        # print(f\"Imputing {col} with mode\")\n",
    "        train_df[col].fillna(train_df[col].mode()[0], inplace=True)\n",
    "\n",
    "for col in test_df.columns:\n",
    "    if test_df[col].isnull().sum() > 0:\n",
    "        # print(f\"Imputing {col} with mode\")\n",
    "        test_df[col].fillna(test_df[col].mode()[0], inplace=True)\n",
    "# Check if there are any missing values\n",
    "print(\"Missing Data in the training dataset (%)\")\n",
    "print(\"=\"*100)\n",
    "print((train_df.isnull().sum()/len(train_df)*100).sort_values(ascending = False).round(3))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned data\n",
    "train_df.to_csv(f\"/kaggle/working/train_cleaned.csv\" if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else f\"Output\\\\train_cleaned.csv\", index=False)\n",
    "test_df.to_csv(f\"/kaggle/working/test_cleaned.csv\" if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else f\"Output\\\\test_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #999999; padding: 10px; border-radius: 5px; background-color: #282828; max-width: 97.5%; overflow-x: auto;\">\n",
    "<p>\n",
    "Here we successfully:\n",
    "<br> - 1. remove all the mistyped entries in categorical features, \n",
    "<br> - 2. reduce the number of unique values in each feature by grouping values contributing to less than 5% of the total count into a new option \"Other\", and \n",
    "<br> - 3. impute the missing value with the most frequent option in a feature.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4. Summary of the dataset by ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile=ProfileReport(train_df,title='Pandas Profiling Report',explorative=True)\n",
    "# profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Preprocessing\n",
    "\n",
    "Next, we preprocess the data by further imputing the missing values, one hot encoding the options in every features and label encoding the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# visualizing pipeline\n",
    "set_config(display='diagram')\n",
    "\n",
    "# Define a function to preprocess the data\n",
    "def PreprocessData(df):\n",
    "    \n",
    "    '''\n",
    "    This function preprocesses the data by imputing missing values and scaling the numerical features.\n",
    "    '''\n",
    "\n",
    "    # Define the numerical and categorical features\n",
    "    num_features = df._get_numeric_data().columns\n",
    "    cat_features = list(set(df.columns) - set(num_features))\n",
    "\n",
    "    # Set up the numerical and categorical transformers\n",
    "    numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputation_mean\",SimpleImputer(missing_values=np.nan,strategy=\"mean\")),\n",
    "          (\"scaler\",StandardScaler())]\n",
    "    )\n",
    "    categorial_transformer = Pipeline(\n",
    "    steps=[(\"imputation_mode\",SimpleImputer(missing_values=np.nan,strategy=\"most_frequent\")),('onehot',OneHotEncoder(handle_unknown='ignore'))]\n",
    "    )\n",
    "    # Set up the preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_features),\n",
    "        ('cat', categorial_transformer, cat_features)\n",
    "    ])\n",
    "\n",
    "    # Fit and transform the data\n",
    "    X = preprocessor.fit_transform(df)\n",
    "\n",
    "    # Return the preprocessed data\n",
    "    return X, preprocessor\n",
    "\n",
    "# Preprocess the data\n",
    "X, preprocessor = PreprocessData(train_df)\n",
    "X1, preprocessor = PreprocessData(test_df)\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 1st Level models\n",
    "\n",
    "Then, we proceed to construct the 1st level models, which begins by defining the models (#6.1) and their parameters (#6.2). In this project, we will tune the hyperparameters by RandomizedSearchCV, and thus a parameter grid is defined in Section 6.2.\n",
    "\n",
    "### 6.1. Model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a utility function to sort the dictionary by values aphabatically\n",
    "def sort_dict(d):\n",
    "    return dict(sorted(d.items(), key=lambda x: x[0]))\n",
    "\n",
    "# Define a list of models for prediction\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(),\n",
    "#     \"MLP Classifier\": MLPClassifier(),\n",
    "    # \"Extra Trees Classifier\": ExtraTreesClassifier(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(estimator = DecisionTreeClassifier(max_depth=1), algorithm='SAMME'),\n",
    "    \"Dummy Classifier\": DummyClassifier(strategy='most_frequent')  # DummyClassifier for sanity check\n",
    "}\n",
    "\n",
    "# Sort the models\n",
    "classifiers=sort_dict(classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the hyperparamter tuning of models by RandomizedSearchCV\n",
    "import scipy.stats as stats\n",
    "\n",
    "params_classifiers = {\n",
    "\n",
    "    \"Logistic Regression\": {\n",
    "        'solver': ['newton-cg', 'sag', 'lbfgs'],  \n",
    "        'penalty': ['l2', None],  \n",
    "        'C': [0.1],\n",
    "        'max_iter': [100, 200, 300]\n",
    "    },\n",
    "\n",
    "    \"Random Forest Classifier\": {\n",
    "        'n_estimators': [64, 128, 256],\n",
    "        'max_depth': [8, 16, 32, 64],\n",
    "        'criterion': ['entropy'],\n",
    "        'warm_start': [False]\n",
    "    },\n",
    "\n",
    "    \"Gradient Boosting Classifier\": {\n",
    "        'learning_rate': stats.loguniform(1e-2, 1e-1),\n",
    "        'n_estimators': [8, 16, 32, 64, 128, 256],\n",
    "        'subsample': [0.6, 0.7, 0.75, 0.8, 0.85, 0.9],\n",
    "    },\n",
    "\n",
    "\n",
    "    \"XGBClassifier\": {\n",
    "            'objective':['binary:logistic'],\n",
    "            'max_depth': [3, 5, 7, 9],\n",
    "            'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
    "            'n_estimators': [16, 32, 64, 128, 256]\n",
    "        },\n",
    "\n",
    "\n",
    "#     \"MLP Classifier\": {\n",
    "#         'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50), (100,)],\n",
    "#         'activation': ['tanh', 'relu'],\n",
    "#         'solver': ['sgd', 'adam'],\n",
    "#         'alpha': stats.loguniform(1e-5, 1e-2),\n",
    "#         'learning_rate': ['constant', 'adaptive']\n",
    "#     },\n",
    "    \n",
    "    # \"Extra Trees Classifier\": {\n",
    "    #     'n_estimators': [128, 256,524],\n",
    "    #     'criterion': ['entropy'],\n",
    "    #     'max_features': [10, 20, 40],\n",
    "    #     'min_samples_split': [2, 5, 10],\n",
    "    #     'min_samples_leaf': [1, 2, 4],\n",
    "    #     'bootstrap': [True, False],\n",
    "    #     'warm_start': [False]\n",
    "    # },\n",
    "\n",
    "    \"AdaBoost Classifier\": {\n",
    "        'n_estimators': [50, 100, 200, 300],\n",
    "        'learning_rate': stats.loguniform(1e-4, 1e-1),\n",
    "    },\n",
    "\n",
    "    \"Dummy Classifier\": {}\n",
    "}\n",
    "\n",
    "# Sort the parameters\n",
    "params_classifiers = sort_dict(params_classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Model training and hyperparameters tuning\n",
    "\n",
    "#### a. Setup scoring method for the model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Setup the KFold\n",
    "NFOLDS = 3 # set folds for out-of-fold prediction\n",
    "kf = StratifiedKFold(n_splits= NFOLDS,shuffle=True, random_state=SEED)\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# Define a custom cost function for the RandomizedSearchCV\n",
    "def MCC(y_true, y_pred):\n",
    "    MCC= matthews_corrcoef(y_true, y_pred)\n",
    "    return MCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Define utility functions for the model evaluations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to obtain the out of fold predictions\n",
    "def get_oof_predictions(model, X_train, y_train, X_test, kf):\n",
    "\n",
    "    \"\"\"\n",
    "    This function trains the model on the training set and returns the out of fold predictions and the test predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the out of fold predictions\n",
    "    oof_predictions = np.zeros((X_train.shape[0],))\n",
    "    # Initialize the test predictions\n",
    "    test_predictions = np.zeros((X_test.shape[0],))\n",
    "\n",
    "    # Loop through the training and validation sets\n",
    "    for train_index, val_index in kf.split(X_train,y_train):\n",
    "        # Split the training and validation sets\n",
    "        X_tr, X_val = X_train[train_index], X_train[val_index]\n",
    "        y_tr, y_val = y_train[train_index], y_train[val_index]\n",
    "        # Fit the model\n",
    "        model.fit(X_tr, y_tr) \n",
    "        # Make predictions\n",
    "        oof_predictions[val_index] = model.predict(X_val)\n",
    "        test_predictions += model.predict(X_test)\n",
    "\n",
    "    # Return the out of fold predictions and the test predictions\n",
    "    return model,oof_predictions, test_predictions / kf.get_n_splits() # Average the test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from joblib import dump, load\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "def model_evaluation(models, X_train, y_train, X_val, y_val, kf,params=None,mode='tuning'):\n",
    "    \"\"\"\n",
    "    This function evaluates the models using the training and validation datasets, and saves them in a directory with the name of the model.\n",
    "    The function returns the MCC scores in a dataframe and saves the results in a csv file.\n",
    "    If activated using the 'tuning' mode, the function tunes the hyperparameters of the models using RandomizedSearchCV.\n",
    "    If activated using the 'training' mode, the function trains the models and returns the out of fold predictions.\n",
    "    \"\"\"\n",
    "    # Initialize the lists to store the results\n",
    "    model_list = []\n",
    "    MCC_train_list = []\n",
    "    MCC_val_list = []\n",
    "    time_list = []\n",
    "    y_train_pred_list = []\n",
    "    model_params = []\n",
    "    # Initialize a dataframe of out of fold predictions for the models\n",
    "    oof_predictions_df = pd.DataFrame()\n",
    "    # Initialize a dataframe of val predictions for the models\n",
    "    val_predictions_df = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(list(models))):\n",
    "        # check if the model is saved in the dictionary\n",
    "        if os.path.exists((f\"/kaggle/working/{list(models.keys())[i]}\"+\"_\"+mode+\".joblib\" if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else f\"Output\\\\{list(models.keys())[i]}\"+\"_\"+mode+\".joblib\")):\n",
    "            print ('=' * 100)\n",
    "            print ('Loading model:', list(models.keys())[i])\n",
    "            model = load((f\"/kaggle/working/{list(models.keys())[i]}\"+\"_\"+mode+\".joblib\" if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else f\"Output\\\\{list(models.keys())[i]}\"+\"_\"+mode+\".joblib\"))\n",
    "            print ('Predicting')\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "\n",
    "            MCC_train = MCC(y_train, y_train_pred)\n",
    "            MCC_val = MCC(y_val, y_val_pred)\n",
    "\n",
    "            model_list.append(list(models.keys())[i])\n",
    "            MCC_train_list.append(MCC_train)\n",
    "            MCC_val_list.append(MCC_val)\n",
    "            y_train_pred_list.append(y_train_pred)\n",
    "            model_params.append(model.get_params())\n",
    "\n",
    "            # read the oof predictions and val predictions from the csv file if the mode is 'training'\n",
    "            if mode == 'training':\n",
    "                oof_predictions = pd.read_csv(f\"/kaggle/working/oof_predictions.csv\" if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else f\"Output\\\\oof_predictions.csv\")\n",
    "                val_predictions = pd.read_csv(f\"/kaggle/working/val_predictions.csv\" if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else f\"Output\\\\val_predictions.csv\")\n",
    "                oof_predictions_df[list(models.keys())[i]] = oof_predictions[list(models.keys())[i]]\n",
    "                val_predictions_df[list(models.keys())[i]] = val_predictions[list(models.keys())[i]]\n",
    "\n",
    "            print('Model_loading success:', list(models.keys())[i], 'MCC_train:', MCC_train, ' , MCC_val:', MCC_val)\n",
    "            print('=' * 100)\n",
    "            print('\\n')\n",
    "        else:\n",
    "            try:\n",
    "                model = list(models.values())[i]\n",
    "                print ('=' * 100)\n",
    "                print ('Running model:', list(models.keys())[i])\n",
    "                \n",
    "                if mode == 'tuning':\n",
    "                    para = params[list(models.keys())[i]]\n",
    "                    # Tune the hyperparameters of the models using RandomizedSearchCV\n",
    "                    if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
    "                        RS = RandomizedSearchCV(model, para, n_iter=5, scoring=make_scorer(MCC, greater_is_better=True), refit=True, n_jobs=-1, verbose=1)\n",
    "                    else:\n",
    "                        RS = RandomizedSearchCV(model, para, n_iter=5, scoring=make_scorer(MCC, greater_is_better=True), refit=True, n_jobs=6, verbose=1)\n",
    "                    RS.fit(X_train, y_train)\n",
    "                    best_model = RS.best_estimator_\n",
    "                    model_params.append(RS.best_params_)\n",
    "                    print('Model-tuning success:', list(models.keys())[i], 'Best Parameters:', RS.best_params_)\n",
    "\n",
    "                elif mode == 'training':\n",
    "                    # Get the out of fold predictions and the val predictions\n",
    "                    best_model,oof_predictions, val_predictions = get_oof_predictions(model, X_train, y_train, X_val, kf)\n",
    "                    # Add the out of fold predictions to the dataframe\n",
    "                    oof_predictions_df[list(models.keys())[i]] = oof_predictions\n",
    "                    # Add the val predictions to the dataframe\n",
    "                    val_predictions_df[list(models.keys())[i]] = val_predictions\n",
    "                    print('Model-training success:', list(models.keys())[i])\n",
    "                    # Save the predictions in a csv file\n",
    "                    oof_predictions_df.to_csv(f\"/kaggle/working/oof_predictions.csv\" if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else f\"Output\\\\oof_predictions.csv\", index=False)\n",
    "                    val_predictions_df.to_csv(f\"/kaggle/working/val_predictions.csv\" if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else f\"Output\\\\val_predictions.csv\", index=False)\n",
    "\n",
    "                # Make predictions\n",
    "                print ('Predicting')\n",
    "                y_train_pred = best_model.predict(X_train)\n",
    "                y_val_pred = best_model.predict(X_val)\n",
    "\n",
    "                # Evaluate Train and val dataset\n",
    "                MCC_train = MCC(y_train, y_train_pred)\n",
    "                MCC_val = MCC(y_val, y_val_pred)\n",
    "\n",
    "                # Append the results to the lists\n",
    "                model_list.append(list(models.keys())[i])\n",
    "                MCC_train_list.append(MCC_train)\n",
    "                MCC_val_list.append(MCC_val)\n",
    "                y_train_pred_list.append(y_train_pred)\n",
    "\n",
    "                # Save the best parameters in a directory with the name of the model\n",
    "                dump(best_model, f\"/kaggle/working/{list(models.keys())[i]}\"+\"_\"+mode+\".joblib\" if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else f\"Output\\\\{list(models.keys())[i]}\"+\"_\"+mode+\".joblib\", protocol=5)\n",
    "                \n",
    "                print('Model Success:', list(models.keys())[i], 'MCC_train:', MCC_train, ' , MCC_val:', MCC_val)\n",
    "                print('=' * 100)\n",
    "                print('\\n')\n",
    "\n",
    "            # Raise exception if the model fails\n",
    "            except Exception as e:\n",
    "                print(list(models.keys())[i])\n",
    "                model_list.append(list(models.keys())[i])\n",
    "                MCC_train_list.append(np.nan)\n",
    "                MCC_val_list.append(np.nan)\n",
    "                y_train_pred_list.append(np.nan)\n",
    "                model_params.append(np.nan)\n",
    "                print('Model failed:', e)\n",
    "                print('=' * 100)\n",
    "                print('\\n')\n",
    "                continue\n",
    "\n",
    "    # save the results in a dataframe\n",
    "    results = pd.DataFrame({'Model': model_list, 'MCC_train': MCC_train_list, 'MCC_val': MCC_val_list})\n",
    "    # save the results in a csv file\n",
    "\n",
    "\n",
    "    results.to_csv(f\"/kaggle/working/results_\"+mode+'.csv' if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else f'Output/results_'+mode+'.csv', index=False)\n",
    "    if mode == 'tuning':\n",
    "        return model_list, MCC_train_list, MCC_val_list, y_train_pred_list, model_params\n",
    "    elif mode == 'training':\n",
    "        return model_list, MCC_train_list, MCC_val_list, y_train_pred_list, oof_predictions_df, val_predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4. Hyperparameter tuning using a smaller set of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #999999; padding: 10px; border-radius: 5px; background-color: #282828; max-width: 97.5%; overflow-x: auto;\">\n",
    "<p>\n",
    "<br>- Because we have a huge dataset, I decided to use a subset of which for tuning the hyperparameters and select models. The selected models will then be retrained in the whole dataset.\n",
    "<br>- We made a subset of sample size= 100000, and\n",
    "<br>- We selected models which show MCC score > 0.8 for further training.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Loading model: AdaBoost Classifier\n",
      "Predicting\n",
      "Model_loading success: AdaBoost Classifier MCC_train: 0.1558191554842848  , MCC_val: 0.1648088877043272\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Loading model: Dummy Classifier\n",
      "Predicting\n",
      "Model_loading success: Dummy Classifier MCC_train: 0.0  , MCC_val: 0.0\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Loading model: Gradient Boosting Classifier\n",
      "Predicting\n",
      "Model_loading success: Gradient Boosting Classifier MCC_train: 0.09325607768533681  , MCC_val: 0.10449424059154264\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Loading model: Logistic Regression\n",
      "Predicting\n",
      "Model_loading success: Logistic Regression MCC_train: -0.01694760650618448  , MCC_val: -0.008132128458198426\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Loading model: Random Forest Classifier\n",
      "Predicting\n",
      "Model_loading success: Random Forest Classifier MCC_train: 0.16291755708579972  , MCC_val: 0.17843221240164578\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Loading model: XGBClassifier\n",
      "Predicting\n",
      "Model_loading success: XGBClassifier MCC_train: 0.09622803731877504  , MCC_val: 0.11290066645276797\n",
      "====================================================================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MCC_Score_Train_sample</th>\n",
       "      <th>MCC_Score_val_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>-0.016948</td>\n",
       "      <td>-0.008132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dummy Classifier</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.093256</td>\n",
       "      <td>0.104494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.096228</td>\n",
       "      <td>0.112901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>0.155819</td>\n",
       "      <td>0.164809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.162918</td>\n",
       "      <td>0.178432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Name  MCC_Score_Train_sample  MCC_Score_val_sample\n",
       "3           Logistic Regression               -0.016948             -0.008132\n",
       "1              Dummy Classifier                0.000000              0.000000\n",
       "2  Gradient Boosting Classifier                0.093256              0.104494\n",
       "5                 XGBClassifier                0.096228              0.112901\n",
       "0           AdaBoost Classifier                0.155819              0.164809\n",
       "4      Random Forest Classifier                0.162918              0.178432"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling data for hyperparameter tuning\n",
    "sample_size = 100000  # sample size for tuning\n",
    "X_sample, _, y_sample, _ = train_test_split(X, y, train_size=sample_size, stratify=y, random_state=42)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train_sample, X_val_sample, y_train_sample, y_val_sample = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42, stratify=y_sample)\n",
    "\n",
    "# MCC Scores\n",
    "model_list_tuning, MCC_train_list_tuning, MCC_val_list_tuning,y_train_pred_list_tuning, model_params_tuning = model_evaluation(classifiers, X_train_sample, y_train_sample, X_val_sample, y_val_sample, kf, params= params_classifiers, mode='tuning')\n",
    "\n",
    "# Display the scores\n",
    "pd.DataFrame(list(zip(model_list_tuning, MCC_train_list_tuning, MCC_val_list_tuning)), columns=['Model Name', 'MCC_Score_Train_sample', 'MCC_Score_val_sample']).sort_values(by=[\"MCC_Score_val_sample\"],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifiers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m models_selected \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m parameters_selected \u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(classifiers))):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m MCC_val_list_tuning[i] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.9\u001b[39m:\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(classifiers\u001b[38;5;241m.\u001b[39mkeys())[i])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classifiers' is not defined"
     ]
    }
   ],
   "source": [
    "# Obtain a subset of models that has MCC_Score_val > 0.9\n",
    "models_selected = []\n",
    "parameters_selected =[]\n",
    "for i in range(len(list(classifiers))):\n",
    "    if MCC_val_list_tuning[i] > 0.9:\n",
    "        print(list(classifiers.keys())[i])\n",
    "        models_selected.append(list(classifiers.keys())[i])\n",
    "        parameters_selected.append(model_params_tuning[i])\n",
    "\n",
    "# Display the selected models\n",
    "models_selected\n",
    "\n",
    "# Select the models from the classifiers dictionary\n",
    "classifiers_selected = {key: classifiers[key] for key in models_selected}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Train the models with the best parameters with the entire dataset and produce Out of Fold Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #999999; padding: 10px; border-radius: 5px; background-color: #282828; max-width: 97.5%; overflow-x: auto;\">\n",
    "<p>\n",
    "<br> - After collecting the best parameter set, we put back the configs into the models and train them with the entire set.  \n",
    "<br> - At the same time, we obtain the Out-of-fold predictions for ensembling the mets-model.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Running model: Gradient Boosting Classifier\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Add the best parameters to the models\n",
    "for i in range(len(list(classifiers_selected))):\n",
    "    classifiers_selected[list(classifiers_selected.keys())[i]].set_params(**parameters_selected[i])\n",
    "\n",
    "# Train the models with the entire dataset\n",
    "model_list_training, MCC_train_list_training, MCC_val_list_training, y_train_pred_list_training, oof_predictions_df_selected, val_predictions_df_selected = model_evaluation(classifiers_selected, X_train, y_train, X_val, y_val, kf, params=parameters_selected, mode='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation fmin which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# plot a heatmap of the correlation matrix of the out of fold predictions\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(oof_predictions_df_selected\u001b[38;5;241m.\u001b[39mcorr(), annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorrelation Matrix of Out of Fold Predictions\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\seaborn\\matrix.py:446\u001b[0m, in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Plot rectangular data as a color-encoded matrix.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03mThis is an Axes-level function and will draw the heatmap into the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    443\u001b[0m \n\u001b[0;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# Initialize the plotter object\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m plotter \u001b[38;5;241m=\u001b[39m _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[0;32m    447\u001b[0m                       annot_kws, cbar, cbar_kws, xticklabels,\n\u001b[0;32m    448\u001b[0m                       yticklabels, mask)\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Add the pcolormesh kwargs here\u001b[39;00m\n\u001b[0;32m    451\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinewidths\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m linewidths\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\seaborn\\matrix.py:163\u001b[0m, in \u001b[0;36m_HeatMapper.__init__\u001b[1;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mylabel \u001b[38;5;241m=\u001b[39m ylabel \u001b[38;5;28;01mif\u001b[39;00m ylabel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# Determine good default values for the colormapping\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_determine_cmap_params(plot_data, vmin, vmax,\n\u001b[0;32m    164\u001b[0m                             cmap, center, robust)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# Sort out the annotations\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m annot \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m annot \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\seaborn\\matrix.py:202\u001b[0m, in \u001b[0;36m_HeatMapper._determine_cmap_params\u001b[1;34m(self, plot_data, vmin, vmax, cmap, center, robust)\u001b[0m\n\u001b[0;32m    200\u001b[0m         vmin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanpercentile(calc_data, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 202\u001b[0m         vmin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmin(calc_data)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vmax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m robust:\n",
      "File \u001b[1;32mc:\\Users\\Kai Qi Yan\\anaconda3\\envs\\MLEnv\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:343\u001b[0m, in \u001b[0;36mnanmin\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m    338\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m where\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(a) \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;129;01mand\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;66;03m# Fast, but not safe for subclasses of ndarray, or object arrays,\u001b[39;00m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;66;03m# which do not implement isnan (gh-9009), or fmin correctly (gh-8975)\u001b[39;00m\n\u001b[1;32m--> 343\u001b[0m     res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfmin\u001b[38;5;241m.\u001b[39mreduce(a, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(res)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    345\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll-NaN slice encountered\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[0;32m    346\u001b[0m                       stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation fmin which has no identity"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a heatmap of the correlation matrix of the out of fold predictions\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(oof_predictions_df_selected.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix of Out of Fold Predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MCC_Score_Train</th>\n",
       "      <th>MCC_Score_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extra Trees Classifier</td>\n",
       "      <td>0.974288</td>\n",
       "      <td>0.974178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Name  MCC_Score_Train  MCC_Score_val\n",
       "0  Extra Trees Classifier         0.974288       0.974178"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the scores\n",
    "pd.DataFrame(list(zip(model_list_training, MCC_train_list_training, MCC_val_list_training)), columns=['Model Name', 'MCC_Score_Train', 'MCC_Score_val']).sort_values(by=[\"MCC_Score_val\"],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test dataset\n",
    "test_predictions_df_selected = pd.DataFrame()\n",
    "for i,key in enumerate (list(classifiers_selected.keys())):\n",
    "    test_predictions_df_selected[list(classifiers_selected.keys())[i]] = classifiers_selected[key].predict(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Meta-model via MLPClassifier\n",
    "\n",
    "<div style=\"border: 2px solid #999999; padding: 10px; border-radius: 5px; background-color: #282828; max-width: 97.5%; overflow-x: auto;\">\n",
    "<p>\n",
    "<br> - Next, we used the Out-of-fold predictions as inputs to train a, second-level, meta-model with MLPClassifier. \n",
    "<br> - the hyperparameters of the meta-model is also tuned by randomized search. \n",
    "</p>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                   estimator=MLPClassifier(activation=&#x27;tanh&#x27;,\n",
       "                                           hidden_layer_sizes=(50, 50, 50),\n",
       "                                           learning_rate=&#x27;adaptive&#x27;,\n",
       "                                           random_state=42),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000020910D55150&gt;,\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(50, 50, 50),\n",
       "                                                               (50, 100, 50),\n",
       "                                                               (100,)],\n",
       "                                        &#x27;learning_rate&#x27;: [&#x27;constant&#x27;,\n",
       "                                                          &#x27;adaptive&#x27;],\n",
       "                                        &#x27;solver&#x27;: [&#x27;sgd&#x27;, &#x27;adam&#x27;]},\n",
       "                   scoring=make_scorer(MCC, greater_is_better=False, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                   estimator=MLPClassifier(activation=&#x27;tanh&#x27;,\n",
       "                                           hidden_layer_sizes=(50, 50, 50),\n",
       "                                           learning_rate=&#x27;adaptive&#x27;,\n",
       "                                           random_state=42),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000020910D55150&gt;,\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(50, 50, 50),\n",
       "                                                               (50, 100, 50),\n",
       "                                                               (100,)],\n",
       "                                        &#x27;learning_rate&#x27;: [&#x27;constant&#x27;,\n",
       "                                                          &#x27;adaptive&#x27;],\n",
       "                                        &#x27;solver&#x27;: [&#x27;sgd&#x27;, &#x27;adam&#x27;]},\n",
       "                   scoring=make_scorer(MCC, greater_is_better=False, response_method=&#x27;predict&#x27;),\n",
       "                   verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: MLPClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, alpha=0.0005886576837826384,\n",
       "              hidden_layer_sizes=(50, 50, 50), random_state=42, solver=&#x27;sgd&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, alpha=0.0005886576837826384,\n",
       "              hidden_layer_sizes=(50, 50, 50), random_state=42, solver=&#x27;sgd&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                   estimator=MLPClassifier(activation='tanh',\n",
       "                                           hidden_layer_sizes=(50, 50, 50),\n",
       "                                           learning_rate='adaptive',\n",
       "                                           random_state=42),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['tanh', 'relu'],\n",
       "                                        'alpha': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000020910D55150>,\n",
       "                                        'hidden_layer_sizes': [(50, 50, 50),\n",
       "                                                               (50, 100, 50),\n",
       "                                                               (100,)],\n",
       "                                        'learning_rate': ['constant',\n",
       "                                                          'adaptive'],\n",
       "                                        'solver': ['sgd', 'adam']},\n",
       "                   scoring=make_scorer(MCC, greater_is_better=False, response_method='predict'),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train a meta model with the OOF predictions\n",
    "# Define a MLP Classifier for the meta model\n",
    "meta_model = MLPClassifier(hidden_layer_sizes=(50, 50, 50), activation='tanh', solver='adam', alpha=0.0001, learning_rate='adaptive', random_state=SEED)\n",
    "\n",
    "# Implement a randomized search for the meta-model\n",
    "# Implement a randomized search for the meta-model\n",
    "params_meta = {\n",
    "    'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': stats.loguniform(1e-5, 1e-2),\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "# Setup the RandomizedSearchCV\n",
    "RS_meta = RandomizedSearchCV(meta_model, params_meta, n_iter=10, cv=kf, scoring=make_scorer(MCC, greater_is_better=False),refit=True, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the RandomizedSearchCV\n",
    "RS_meta.fit(oof_predictions_df_selected, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MCC score of the meta-model is: 0.9741776846479555\n"
     ]
    }
   ],
   "source": [
    "# Produce the final predictions from the meta-model\n",
    "y_val_meta = RS_meta.predict(val_predictions_df_selected)\n",
    "# Evaluate the meta-model\n",
    "MCC_meta = MCC(y_val, y_val_meta)\n",
    "print(f'The MCC score of the meta-model is: {MCC_meta}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the best parameters of the meta-model\n",
    "best_meta_model = RS_meta.best_estimator_\n",
    "# Save the best meta-model\n",
    "\n",
    "dump(best_meta_model, \"/kaggle/working/meta_model.joblib\" if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else \"Output/meta_model.joblib\", protocol=5)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "# load the meta model\n",
    "meta_model = load(\"/kaggle/working/meta_model.joblib\" if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else \"Output/meta_model.joblib\")\n",
    "# Make predictions on the test dataset\n",
    "test_predictions_meta = meta_model.predict(test_predictions_df_selected)\n",
    "\n",
    "# Map predictions back to original labels\n",
    "test_pred_class = le.inverse_transform(test_predictions_meta)\n",
    "\n",
    "# Save the predictions in a csv file\n",
    "\n",
    "submission_df = pd.read_csv('/kaggle/input/playground-series-s4e8/sample_submission.csv' if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else 'Input/sample_submission.csv')\n",
    "\n",
    "submission_df['class'] = test_pred_class\n",
    "submission_df.to_csv('/kaggle/working/submission.csv' if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ else 'Output/submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "<div style=\"border: 2px solid #999999; padding: 10px; border-radius: 5px; background-color: #282828; max-width: 97.5%; overflow-x: auto;\">\n",
    "<p>\n",
    "<br> In this project, we have successfully constructed a binary classifier for predicting whether a mushroom is edible or poisonous. \n",
    "\n",
    "<br> For Data-Cleaning: \n",
    "<br> - We cleaned the data by dropping features that has missing entries contributing more than 50% of their total count;\n",
    "<br> - We grouped options with low frequencies into a new option \" Other \";\n",
    "<br> - We impute the mistyped entries and remaining missing entries with the most frequent option in the feature. \n",
    "\n",
    "<br> For Model construction:\n",
    "<br> - We defined some typical classifier, tune their parameters and test their prediction performance over a subset of the training set; \n",
    "<br> - We selected models which gave MCC score > 0.8 to be further trained on the whole dataset and obtain Out-of-fold predictions. \n",
    "<br> - With the OOF predictions, we construct a meta-model with a MLPClassifier. \n",
    "<br> - the Constructed meta-model has a accuracy > 0.98. \n",
    "\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Future Improvements\n",
    "\n",
    "1. Create additional features using AutoML\n",
    "2. Conduct Exploratory Data analysis on the data\n",
    "    -  Explore the possiblity to better imputing the missing values by correlating with other features.\n",
    "3. Use lazypredict for selecting models\n",
    "    https://github.com/shankarpandala/lazypredict \n",
    "4. Use Class for grouping functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
